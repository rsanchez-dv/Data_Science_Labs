{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://www.clearlyrated.com/brand-logo/talent-path\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor and author: [_Dr. Junaid Qazi_](https://www.linkedin.com/in/jqazi/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='L7-Logistic-Regression-Multiclass-Classification'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L7: Logistic Regression -- Multiclass Classification{-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [(L7-1) The dataset, EDA and preprocessing](#(L7-1)-The-dataset-EDA-and-preprocessing)\n",
    "* [(L7-2) One vs rest](#(L7-2)-One-vs-rest)\n",
    "* [(L7-3) Multinomial](#(L7-3)-multinomial)\n",
    "* [(L7-4) Predicted probabilities](#(L7-4)-Predicted-probabilities)\n",
    "* [(L7-5) Readings](#(L7-5)-Readings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is one of the most popular and widely used classification algorithm and by default, it is limited to a binary class classification problem. However, the logistic regression can be used for multi-class classification as well using its extension like one-vs-rest (ovr) and multinomial. \n",
    "\n",
    "* In one-vs-rest, the problem is first transformed into multiple binary classification problems, and under the hood, separate binary classifiers are trained for all classes. \n",
    "\n",
    "* whereas, for the multinomial, the solvers learns a true multinomial logistic regression model ([4.3.4: Pattern Recognition and Machine Learning by Christopher M. Bishop](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)) and the in this case, the probability estimates should be better calibrated than one-vs-rest. The [cross-entropy error/loss function](https://en.wikipedia.org/wiki/Cross_entropy) (eq: 4.108 in 4.3.4) natively support multi-class classification problem. -- maximum likelihood estimation\n",
    "\n",
    "Let's work with a multi-class classification problem using both of the above mentioned extensions in logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid') # just optional!\n",
    "%matplotlib inline\n",
    "\n",
    "#Setting display format to retina in matplotlib to see better quality images.\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "\n",
    "# Lines below are just to ignore warnings\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with very famous the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris). It is on classifying three flower type based on some given features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='(L7-1)-The-dataset-EDA-and-preprocessing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (L7-1) The dataset, EDA and preprocessing {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"https://raw.githubusercontent.com/junaidqazi/\\\n",
    "DataSets_Practice_ScienceAcademy/master/Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Id` column is extra, we can drop this column. We can also convert `Species` column to categorical codes. Let's do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.drop('Id', axis=1, inplace=True) # dropping Id column\n",
    "iris_df['target']=iris_df.Species.astype('category').cat.codes # creating codes for categories in target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   SepalLengthCm  150 non-null    float64\n",
      " 1   SepalWidthCm   150 non-null    float64\n",
      " 2   PetalLengthCm  150 non-null    float64\n",
      " 3   PetalWidthCm   150 non-null    float64\n",
      " 4   Species        150 non-null    object \n",
      " 5   target         150 non-null    int8   \n",
      "dtypes: float64(4), int8(1), object(1)\n",
      "memory usage: 6.1+ KB\n"
     ]
    }
   ],
   "source": [
    "iris_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good, there is no missing data. `Species` and `target` columns are actually the same but different types. We just need one and will handle in separating the features and target. \n",
    "\n",
    "The target column has balanced class distribution, 50 observations from each class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some required imports from scikit-learn {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating features and the target {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are completely balanced. For illustration purposes, we\n",
    "create a subset with class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# the classes are completely balanced\n",
    "# create a subset with class imbalance\n",
    "#y = data.target#[:-20]\n",
    "#X = data.data#[:-20]\n",
    "#print (X,y)\n",
    "X = iris_df.drop(['Species', 'target'], axis=1)# features or predictors\n",
    "y = iris_df.target # target "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature scaling {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "# You can try MinMaxScaler and re-run the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine learning {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know it's a multi-class classification problem, let's explicitly compare `ovr` one-vs-rest and `multinomial` approaches. \n",
    "\n",
    "*`<shift-tab>` to explore the documentation, see what happen if `multi_class='auto'` and the problem is multi-class.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to: L7: Logistic Regression -- Mulitclass Classification](#L7-Logistic-Regression-Multiclass-Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='(L7-2)-One-vs-rest'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (L7-2) One-vs-rest {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score when multi_class='ovr': 0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "# Creating model instances\n",
    "logR_ovr = LogisticRegression(multi_class='ovr') # one-vs-rest\n",
    "# fitting the model\n",
    "logR_ovr.fit(X,y)\n",
    "# Accuracy Score \n",
    "print(\"Score when multi_class='ovr':\",logR_ovr.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix and classification reports to explore little more on the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_class='ovr'\n",
      "\n",
      "[[50  0  0]\n",
      " [ 0 37 13]\n",
      " [ 0  3 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.93      0.74      0.82        50\n",
      "           2       0.78      0.94      0.85        50\n",
      "\n",
      "    accuracy                           0.89       150\n",
      "   macro avg       0.90      0.89      0.89       150\n",
      "weighted avg       0.90      0.89      0.89       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions \n",
    "pred_ovr = logR_ovr.predict(X)\n",
    "# Confusion matrix and classification report\n",
    "print(\"multi_class='ovr'\\n\")\n",
    "print(metrics.confusion_matrix(y,pred_ovr,labels=[0, 1, 2]))\n",
    "print(metrics.classification_report(y,pred_ovr,labels=[0, 1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to: L7: Logistic Regression -- Mulitclass Classification](#L7-Logistic-Regression-Multiclass-Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='(L7-3)-multinomial'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (L7-3) Multinomial {-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score when multi_class='multinomial': 0.94\n"
     ]
    }
   ],
   "source": [
    "# Creating model instances\n",
    "logR_mul = LogisticRegression(multi_class='multinomial') # multinomial\n",
    "# fitting both models \n",
    "logR_mul.fit(X,y)\n",
    "# Accuracy score \n",
    "print(\"Score when multi_class='multinomial':\",logR_mul.score(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, as expected, the `multinomial` is giving the better accuracy! \n",
    "\n",
    "Let's look at the confusion matrix and classification reports to explore little more on the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi_class='multinomial'\n",
      "\n",
      "[[50  0  0]\n",
      " [ 0 45  5]\n",
      " [ 0  4 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.92      0.90      0.91        50\n",
      "           2       0.90      0.92      0.91        50\n",
      "\n",
      "    accuracy                           0.94       150\n",
      "   macro avg       0.94      0.94      0.94       150\n",
      "weighted avg       0.94      0.94      0.94       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predictions \n",
    "pred_mul = logR_mul.predict(X)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "print(\"multi_class='multinomial'\\n\")\n",
    "print(metrics.confusion_matrix(y,pred_mul,labels=[0, 1, 2]))\n",
    "print(metrics.classification_report(y,pred_mul,labels=[0, 1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Little more on multiclass logistic regression (optional read)**\n",
    "\n",
    "\n",
    "Multiclass logistic regression is also known as polytomous logistic regression, multinomial logistic regression, softmax regression, multinomial logit (mlogit), the maximum entropy (MaxEnt) classifier, and the conditional maximum entropy model.\n",
    "\n",
    "The multinomial logistic regression assumes that the odds of preferring a certain class over other/s do not depend on the presence of absence of other irrelevant alternatives. So the model choices are [independent of irrelevant alternatives](https://en.wikipedia.org/wiki/Independence_of_irrelevant_alternatives), which is a core hypothesis in relational choice theory. A typical example in predicting animal from images that we can think of, the relative probabilities of predicting a horse or cat don't not change if another choice of lion is added as an additional possibility. \n",
    "\n",
    "* _if class_0 is a preferred choice over class_1 from the given choices set {class_0, class_1}, then by adding another choice of class_3 must not make the class_1 preferable on class_0 from the new set of choices {class_0, class_1, class_2}._\n",
    "\n",
    "This allows the choice of K alternatives to be modeled as a set of K-1 independent binary choices, in which one alternative is chosen as a \"pivot\" and the other K-1 compared against it, one at a time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to: L7: Logistic Regression -- Mulitclass Classification](#L7-Logistic-Regression-Multiclass-Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='(L7-4)-Predicted-probabilities'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (L7-4) Predicted probabilities {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the predicted probabilities as well, which is simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81748599 0.17029348 0.01222053]\n",
      " [0.73774929 0.25155208 0.01069863]]\n"
     ]
    }
   ],
   "source": [
    "# probabilities when using one-vs-rest\n",
    "print(logR_ovr.predict_proba(X)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.89388834 0.10251261 0.00359905]\n",
      " [0.83386212 0.16201348 0.0041244 ]]\n"
     ]
    }
   ],
   "source": [
    "# probabilities when using miltinomial\n",
    "print(logR_mul.predict_proba(X)[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create the ROC curve for our multi-class problem, however, we need to treat the problem as binary class and we will have multiple curves. ROC is only possible for binary class problem. This link in the reading will be useful if you want to create ROC curve for multi-class classification problem: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go to: L7: Logistic Regression -- Mulitclass Classification](#L7-Logistic-Regression-Multiclass-Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='(L7-5)-Readings'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='(L7-6)-Code-examples'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (L7-6) Extra Reading and resources:{-} \n",
    "\n",
    "* [**Data Science from Scratch -- Part 1: Advance Analytics**](https://leanpub.com/data-science-from-scratch)\n",
    "\n",
    "* [**Data Science from Scratch -- Part 2: Business Machine Learning**](https://leanpub.com/datascience-from-scratch-p2-business-machine-learning/c/r1W4Bml3Zqr6)\n",
    "\n",
    "\n",
    "## License\n",
    "\n",
    "Author: [___Dr. Junaid Qazi___](https://www.linkedin.com/in/jqazi/)<br>\n",
    "Twitter: [***@JunaidSQazi***](https://twitter.com/JunaidSQazi)\n",
    "\n",
    "Copyright 2021\n",
    "\n",
    "Licensed under the [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0) (the \"License\").<br>you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "*Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. Please see the License for the specific language governing permissions and limitations under the License.*\n",
    "\n",
    "\n",
    "*This is not an official product but sample code provided for an educational purpose.*\n",
    "\n",
    "***Acknowledgement is requested***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lesson Guide",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
